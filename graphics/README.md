# Grahics Papers
Papers from graphics conferences such as SIGGRAPH, Eurographics, and Pacific Graphics


## SIGGRAPH
* `SIGGRAPH2020` Learning Temporal Coherence via Self-Supervision for GAN-Based Video Generation [[code]](https://github.com/thunil/TecoGAN)
* `SIGGRAPH2020` One Shot 3D Photography [[code]](https://github.com/facebookresearch/one_shot_3d_photography))
* `SIGGRAPH2020` DeepMag: Source Specific Motion Magnification Using Gradient Ascent 
* `SIGGRAPH2020` Portrait Shadow Manipulation [[code]](https://github.com/google/portrait-shadow-manipulation)
* `SIGGRAPH2020` Single Image HDR Reconstruction Using a CNN with Masked Features and Perceptual Loss [[link]](http://faculty.cs.tamu.edu/nimak/Papers/SIGGRAPH2020_HDR/)
* `SIGGRAPH2020` Consistent Video Depth Estimation [[link]](https://roxanneluo.github.io/Consistent-Video-Depth-Estimation/)
* `SIGGRAPH2020` Human-in-the-Loop Differential Subspace Search in High-Dimensional Latent Space [[link]](http://www.cg.it.aoyama.ac.jp/yonghao/sig20/abstsig20.html)
* `SIGGRAPH2020` MichiGAN: Multi-Input-Conditioned Hair Image Generation for Portrait Editing [[link]](https://mlchai.com/files/tan2020michigan.pdf)[[code]](https://github.com/tzt101/MichiGAN)
* `SIGGRAPH2020` Skeleton-Aware Networks for Deep Motion Retargeting [[code]](https://github.com/DeepMotionEditing/deep-motion-editing)
* `SIGGRAPH2020` Unpaired Motion Style Transfer from Video to Animation [[code]](https://github.com/DeepMotionEditing/deep-motion-editing)
* `SIGGRAPH2020` CARL: Controllable Agent with Reinforcement Learning for Quadruped Locomotion [[link]](https://inventec-ai-center.github.io/projects/CARL/index.html)
* `SIGGRAPH2020` Interactive Video Stylization Using Few-Shot Patch-Based Training [[link]](https://ondrejtexler.github.io/patch-based_training/)[[code]](https://github.com/OndrejTexler/Few-Shot-Patch-Based-Training)
* `SIGGRAPH2020` Manipulating Attributes of Natural Scenes via Hallucination [[link]](https://hucvl.github.io/attribute_hallucination/)[[code]](https://github.com/hucvl/attribute_hallucination)
* `SIGGRAPH2020` XNect: Real-time Multi-Person 3D Motion Capture with a Single RGB Camera [[link]](http://gvv.mpi-inf.mpg.de/projects/XNect/)
* `SIGGRAPH2020` RigNet: Neural Rigging for Articulated Characters [[link]](https://zhan-xu.github.io/rig-net/)[[code]](https://github.com/zhan-xu/RigNet)
* `SIGGRAPH2020` Example-driven Virtual Cinematography by Learning Camera Behavior [[link]](https://jianghd1996.github.io/publication/sig_2020/)[[code]](https://github.com/jianghd1996/Camera-control/tree/master/SIGGRAPH_2020)
* `SIGGRAPH2019` VR Facial Animation via Multiview Image Translation [[link]](https://research.fb.com/publications/vr-facial-animation-via-multiview-image-translation/)
* `SIGGRAPH2019` Hyperparameter Optimization in Black-box Image Processing using Differentiable Proxies [[link]](https://www.cs.princeton.edu/~fheide/proxyopt)
* `SIGGRAPH2019` Semantic Photo Manipulation With a Generative Image Prior [[link]](http://ganpaint.io/)
* `SIGGRAPH2019` TileGAN: Synthesis of Large-Scale Non-Homogeneous Textures  [[code]](https://github.com/afruehstueck/tileGAN)
* `SIGGRAPH2019` Progressive Color Transfer with Dense Semantic Correspondences [[link]](https://arxiv.org/pdf/1710.00756.pdf)
* `SIGGRAPH2019` The Face of Art: Landmark Detection and Geometric Style in Portraits [[link]](http://www.faculty.idc.ac.il/arik/site/foa/face-of-art.asp)[[code]](https://github.com/papulke/face-of-art)
* `SIGGRAPH2019` Distortion-Free Wide-Angle Portraits on Camera Phones [[link]](http://people.csail.mit.edu/yichangshih/wide_angle_portrait/)
* `SIGGRAPH2019` Interactive and Automatic Navigation for 360° Video Playback [[link]](https://vclab.dgist.ac.kr/interactive360/)
* `SIGGRAPH2019` Joint Stabilization and Direction of 360° Videos [[link]](https://dl.acm.org/citation.cfm?doid=3313807.3211889)
* `SIGGRAPH2019` Text-based Editing of Talking-head Video[[link]](https://www.ohadf.com/projects/text-based-editing/)
* `SIGGRAPH2019` Single Image Portrait Relighting [[link]](https://arxiv.org/pdf/1905.00824.pdf)
* `SIGGRAPH2019` Local Light Field Fusion: Practical View Synthesis with Prescriptive Sampling Guidelines [[link]](http://people.eecs.berkeley.edu/~bmild/llff/) [[code]](https://github.com/Fyusion/LLFF)
* `SIGGRAPH2019` Multi-view Relighting using a Geometry-Aware Network [[link]](https://repo-sam.inria.fr/fungraph/deep-relighting/)
* `SIGGRAPH2019` Learning Character-Agnostic Motion for Motion Retargeting in 2D [[link]](https://motionretargeting2d.github.io/)[[code]](https://github.com/ChrisWu1997/2D-Motion-Retargeting)
* `SIGGRAPH2019` Synthetic Defocus and Look-Ahead Autofocus for Casual Videograph [[link]](https://ceciliavision.github.io/vid-auto-focus/)
* `SIGGRAPH2019` Video Extrapolation Using Neighboring Frames [[link]](https://vml.kaist.ac.kr/main/international/individual/157)
* `SIGGRAPH2019` Physics-based Full-body Soccer Motion Control for Dribbling and Shooting [[link]](https://vml.kaist.ac.kr/main/international/individual/156)
* `SIGGRAPH2019` Neural Rendering and Reenactment of Human Actor Videos [[link]](http://gvv.mpi-inf.mpg.de/projects/wxu/HumanReenactment/)
* `SIGGRAPH2019` Deferred Neural Rendering: Image Synthesis using Neural Textures [[link]](https://niessnerlab.org/projects/thies2019neural.html)
* `SIGGRAPH2019` Deep View Synthesis from Sparse Photometric Images [[link]](http://cseweb.ucsd.edu/~ravir/zexiangview.pdf)
* `SIGGRAPH2019` Stylizing Video by Example [[link]](https://dcgi.fel.cvut.cz/home/sykorad/ebsynth.html)
* `SIGGRAPH2018` Non-stationary Texture Synthesis by Adversarial Expansion [[link]](http://vcc.szu.edu.cn/research/2018/TexSyn)[[code]](https://github.com/jessemelpolio/non-stationary_texture_syn)
* `SIGGRAPH2018` Semantic Soft Segmentation [[link]](http://people.inf.ethz.ch/aksoyy/sss/)
* `SIGGRAPH2018` Stereo Magnification: Learning View Synthesis using Multiplane Images [[link]](https://people.eecs.berkeley.edu/~tinghuiz/projects/mpi/)
* `SIGGRAPH2018` Instant 3D Photography [[link]](http://visual.cs.ucl.ac.uk/pubs/instant3d/)
* `SIGGRAPH2018` FaceShop: Deep Sketch-based Face Image Editing [[link]](https://arxiv.org/pdf/1804.08972.pdf)
* `SIGGRAPH2018` Deep Image-Based Relighting from Optimal Sparse Samples [[link]](http://cseweb.ucsd.edu/~viscomp/projects/SIG18Relighting/)
* `SIGGRAPH2018` Deep Video Portraits [[link]](https://web.stanford.edu/~zollhoef/papers/SG2018_DeepVideo/page.html)
* `SIGGRAPH2018` ToonSynth: Example-Based Synthesis of Hand-Colored Cartoon Animations [[link]](http://dcgi.fel.cvut.cz/home/sykorad/toonsynth.html)
* `SIGGRAPH2018` Robust Solving of Optical Motion Capture Data by Denoising [[link]](http://montreal.ubisoft.com/en/robust-solving-of-optical-motion-capture-data-by-denoising/)
* `SIGGRAPH2018` MonoPerfCap: Human Performance Capture from Monocular Video [[link]](http://gvv.mpi-inf.mpg.de/projects/wxu/MonoPerfCap/)
* `SIGGRAPH2017` Computational Video Editing for Dialogue-Driven Scenes [[link]](http://graphics.stanford.edu/papers/roughcut/)
* `SIGGRAPH2017` Unmixing-Based Soft Color Segmentation for Image Manipulation [[link]](http://people.inf.ethz.ch/aksoyy/scs/)
* `SIGGRAPH2017` Interactive High-Quality Green-Screen Keying via Color Unmixing [[link]](http://people.inf.ethz.ch/aksoyy/keying/)
* `SIGGRAPH2016` Perspective-aware Manipulation of Portrait Photos [[link]](https://gfx.cs.princeton.edu/pubs/Fried_2016_PMO/index.php)
* `SIGGRAPH2014` 3D Object Manipulation in a Single Photograph using Stock 3D Models[[link]](http://www.cs.cmu.edu/~om3d/)[[code]](http://www.cs.cmu.edu/~om3d/)
* `SIGGRAPH2010` Video Tapestries with Continuous Temporal Zoom [[link]](https://gfx.cs.princeton.edu/pubs/Barnes_2010_VTW/index.php)
* `SIGGRAPH2006` Schematic Storyboarding for Video Visualization and Editing [[link]](https://grail.cs.washington.edu/projects/storyboards/)
* `SIGGRAPH2005` Interactive Video Cutout [[link]](http://juew.org/projects/VideoCutout/VideoCutout.htm)


## SIGGRAPH ASIA
* `SIGASIA2020` Layered Neural Rendering for Retiming People in Video [[link]](https://retiming.github.io/)[[code]]()
* `SIGASIA2020` Neural Crossbreed: Neural Based Image Metamorphosis [[link]](https://arxiv.org/abs/2009.00905)
* `SIGASIA2020` Mononizing Binocular Videos [[link]](https://wbhu.github.io/projects/Mono3D/)
* `SIGASIA2020` MakeItTalk: Speaker-Aware Talking Head Animation [[link]](https://arxiv.org/abs/2004.12992)
* `SIGASIA2020` Pixelor: A Competitive Sketching AI Agent. So you think you can beat me? [[code]](https://github.com/AyanKumarBhunia/sketch-transformerMMD) 
* `SIGASIA2020` Manga Filling with ScreenVAE [[link]](https://www.cse.cuhk.edu.hk/~ttwong/papers/screenstyle/screenstyle.html)
* `SIGASIA2020` Light Stage Super-Resolution: Continuous High-Frequency Relighting [[link]](https://cseweb.ucsd.edu/~ravir/tianchengsiga.pdf)
* `SIGASIA2020` Egocentric Videoconferencing [[lnik]](http://gvv.mpi-inf.mpg.de/projects/EgoChat/)
* `SIGASIA2020` OmniPhotos: Casual 360° VR Photography [[link]](https://richardt.name/publications/omniphotos/)[[code]](https://richardt.name/publications/omniphotos/)
* `SIGASIA2020` Deep Relightable Textures: Volumetric Performance Capture With Neural Rendering [[link]](http://gvv.mpi-inf.mpg.de/projects/DeepRelightableTextures/)
* `SIGASIA2020` X-Fields: Implicit Neural View-, Light- And Time-Image Interpolation [[]](https://xfields.mpi-inf.mpg.de/)[[code]](https://github.com/m-bemana/xfields)
* `SIGASIA2020` Face Disentanglement Via Latent Space Mapping
* `SIGASIA2020` PIE: Portrait Image Embedding For Semantic Control [[link]](http://gvv.mpi-inf.mpg.de/projects/PIE/)
* `SIGASIA2020` Single Image Portrait Relighting Via Explicit Multiple Reflectance Channel Modeling
* `SIGASIA2020` MotioNet: 3D Human Motion Reconstruction from Monocular Video with Skeleton Consistency [[link]](https://rubbly.cn/publications/motioNet/)[[code]](https://github.com/Shimingyi/MotioNet)
* `SIGASIA2020` MoGlow: Probabilistic And Controllable Motion Synthesis Using Normalising Flows
* `SIGASIA2020` PhysCap: Physically Plausible Monocular 3D Motion Capture In Real Time [[link]](http://gvv.mpi-inf.mpg.de/projects/PhysCap/)
* `SIGASIA2020` Speech Gesture Generation From The Trimodal Context Of Text, Audio, And Speaker Identity [[code]](https://github.com/ai4r/Gesture-Generation-from-Trimodal-Context)
* `SIGASIA2020` Dynamic Facial Asset and Rig Generation from a Single Scan [[link]]()
* `SIGASIA2020` A Reduced-Precision Network For Image Reconstruction [[link]](https://creativecoding.soe.ucsc.edu/QW-Net/)[[code]](https://creativecoding.soe.ucsc.edu/QW-Net/)
* `SIGASIA2020` SketchPatch: Sketch Stylization Via Seamless Patch-Level Synthesis
* `SIGASIA2020` Differentiable Vector Graphics Rasterization For Editing And Learning [[link]](https://people.csail.mit.edu/tzumao/diffvg/)[[code]](https://github.com/BachiLi/diffvg)
* `SIGASIA2020` Complementary Dynamics [[link]](https://www.dgp.toronto.edu/projects/complementary-dynamics/)
* `SIGASIA2020` Monster Mash: A Single-View Approach To Casual 3D Modeling And Animation [[link]](https://dcgi.fel.cvut.cz/home/sykorad/)
* `SIGASIA2020` MaterialGAN: Reflectance Capture Using A Generative SVBRDF Model [[link]](https://shuangz.com/projects/materialgan-sa20/)[[code]](https://shuangz.com/projects/materialgan-sa20/)
* `SIGASIA2020` Deferred Neural Lighting: Free-Viewpoint Relighting From Unstructured Photographs [[link]](https://gao-duan.github.io/)[[code]](https://gao-duan.github.io/)
* `SIGASIA2020` Continuous Curve Textures [[link]](https://www.youtube.com/watch?v=gfogZ7BphvE)
* `SIGASIA2020` A Benchmark For Rough Sketch Cleanup [[link]](https://cragl.cs.gmu.edu/sketchbench/)
* `SIGASIA2019` Handheld Mobile Photography in Very Low Light [[link]](https://github.com/google/night-sight)
* `SIGASIA2019` Learning Efficient Illumination Multiplexing for Joint Capture of Reflectance and Shape [[link]](http://cad.zju.edu.cn/home/hwu/publications/jointcap/project.html)
* `SIGASIA2019` Blind Image Super-Resolution with Spatially Variant Degradations [[link]](https://igl.ethz.ch/projects/variational-blind-sr/) [[code]](https://github.com/sunreef/BlindSR)
* `SIGASIA2019` Document Rectification and Illumination Correction using a Patch-based CNN [[link]](https://xiaoyu258.github.io/projects/docproj/)[[code]](https://github.com/xiaoyu258/DocProj)
* `SIGASIA2019` Animating Landscape [[link]](http://www.npal.cs.tsukuba.ac.jp/~endo/projects/AnimatingLandscape/)[[code]](https://github.com/endo-yuki-t/Animating-Landscape)
* `SIGASIA2019` DeepRemaster [[link]](http://iizuka.cs.tsukuba.ac.jp/projects/remastering/en/index.html)[[code]](https://github.com/satoshiiizuka/SIGASIA2019_remastering)
* `SIGASIA2019` Colorblind-Shareable Videos by Synthesizing Temporal-Coherent Polynomial Coefficients [[link]](https://menghanxia.github.io/)
* `SIGASIA2019` Neural Style-Preserving Visual Dubbing [[link]](https://gvv.mpi-inf.mpg.de/projects/StyleDub/)
* `SIGASIA2019` Deep Face Normalization [[link]](http://luminohope.org/publications.php)
* `SIGASIA2019` Artistic Glyph Image Synthesis via One-Stage Few-Shot Learning [[link]](https://hologerry.github.io/AGIS-Net/)[[code]](https://github.com/hologerry/AGIS-Net)
* `SIGASIA2019` A Novel Framework For Inverse Procedural Texture Modeling [[link]](https://graphics.cs.yale.edu/publications/novel-framework-inverse-procedural-texture-modeling)
* `SIGASIA2019` Write-A-Video: Computational Video Montage from Themed Text [[link]](http://miaowang.me/write-a-video/)
* `SIGASIA2019` DReCon: Data-Driven Responsive Control of Physics-Based Characters [[link]](https://montreal.ubisoft.com/en/drecon-data-driven-responsive-control-of-physics-based-characters/)
* `SIGASIA2019` Neural State Machine for Goal-Directed Character Control [[code]](https://github.com/sebastianstarke/AI4Animation)
* `SIGASIA2019` Deep Iterative Frame Interpolation for Full-frame Video Stabilization[[link]](https://arxiv.org/abs/1909.02641)
* `SIGASIA2019` Language-based Colorization of Scene Sketches [[code]](https://github.com/SketchyScene/SketchySceneColorization)
* `SIGASIA2019` 3D Ken Burns Effect from a Single Image [[link]](http://sniklaus.com/papers/kenburns)
* `SIGASIA2019` LOGAN: Unpaired Shape Transform in Latent Overcomplete Space [[link]](https://arxiv.org/abs/1903.10170)[[code]](https://calendar.google.com/calendar/r)
* `SIGASIA2019` Multi-Style Generative Adversarial Terrain Amplification [[code]](https://github.com/electronicarts/siggraph-asia-2019-gata)
* `SIGASIA2019` The Relightables: Volumetric Performance Capture of Humans with Realistic Relighting [[link]](https://augmentedperception.github.io/therelightables/)
* `SIGASIA2019` An Integrated 6DoF Video Camera and System Design [[link]](https://research.fb.com/publications/an-integrated-6dof-video-camera-and-system-design/)
* `SIGASIA2013` WYSIWYG Computational Photography via Viewfinder Editing [[link]](http://graphics.stanford.edu/papers/wysiwyg)
<!-- * `SIGASIA2019` OpenSketch: A Richly-Annotated Dataset of Product Design Sketches [[link]](https://ns.inria.fr/d3/OpenSketch/)[[code]](https://gitlab.inria.fr/openskecth) -->
<!-- * `SIGASIA2019` Mitsuba 2: A Retargetable Forward and Inverse Renderer [[link]](https://rgl.epfl.ch/publications/NimierDavidVicini2019Mitsuba2) -->

## Pacific Graphics
* `PG2019` Generic Interactive Pixel-Level Image Editing [[link]]()
* `PG2019` Imitating Popular Photos to Select Views for an Indoor Scene [[link]]()
* `PG2019` Learning to Trace: Expressive Line Drawing Generation from Photographs [[link]]()
* `PG2019` Learning Explicit Smoothing Kernels for Joint Image Filtering [[link]]()
* `PG2019` Dual Illumination Estimation for Robust Exposure Correction [[link]]()
* `PG2019` Specular Highlight Removal for Real-World Images [[link]]()
* `PG2019` Naturalness-Preserving Image Tone Enhancement Using Generative Adversarial Networks [[link]]()
* `PG2019` Shadow Inpainting and Removal Using Generative ADversarial Netowrks with Slice Convolutions [[link]](http://www.chengjianglong.com/publications/SCShadow_CGF.pdf)
* `PG2019` Two-Phase Hair Image Synthesis by Self-Enhancing Generative Model [[link]]()
* `PG2019` Unsupervised Desnse Light Field Reconstruction with Occlusion Awareness [[link]]()
* `PG2019` Learning to Paint using Self-Supervised LEarning [[link]]()
* `PG2019` Style Mixser: Semantic-Aware Multi-Style Mixing Network [[link]]()
* `PG2019` A Color-Pair Based Approach For Accurate Color Harmony Estimation [[link]]()
* `PG2019` Deep Video-Based Performance Synthesis from Sparse Multi-View Capture [[link]]()
* `PG2019` Appearance Flow Completion for Novel View Synthesis [[link]]()
* `PG2019` Learning to Predict Image-Based Rendering Artifacts with Respect to a Hidden Reference Image[[link]]()
* `PG2019` Image Composition of Partially Occluded Objects [[link]]()
* `PG2019` A PatchMatch-Based Approach for Matte PRopagation in Videos [[link]]()
* `PG2019` ShutterApp: Spatio-Temporal Exposure Control for Videos [[link]]()


## SIGGRAPH Technical Brief
* `SATB2019` PaintersView: Automatic Suggestion of Optimal Viewpoints for 3D Texture Painting [[link]](https://yamaguchi1024.github.io/paintersview-doc/)
* `SATB2019` The Potential of Light Fields in Media Productions [[link]]()
* `SATB2019` Unpaired Sketch-to-Line Translation via Synthesis of Sketches [[link]]()
* `SATB2019` Interactive editing of performance-based facial animation [[link]](https://dl.acm.org/citation.cfm?id=3365147)
* `SATB2019` Piku Piku Interpolation [[link]](https://dl.acm.org/citation.cfm?id=3365156)
* `SATB2019` A Decomposition Method of Object Transfiguration [[link]](https://dl.acm.org/citation.cfm?id=3365151)
* `SATB2019` Structure-Aware Image Expansion with Global Attention [[link]]()

## START REPORT [[link]](https://sites.google.com/site/drminchen/cgf-info/cgf-stars)
* A Survey on Data-Driven Video Completion
* State of the Art Report on Video-Based Graphics and Video Visualization
* A Comparative Review of Tone-Mapping Algorithms for High Dynamic Range Video
* Intrinsic Decompositions for Image Editing
* The State of the Art in Integrating Machine Learning into Visual Analytics
* A Comprehensive Survey on Sampling-Based Image Matting


## ETC
* `EGSR2020` High-Resolution Neural Face Swapping for Visual Effects [[link]](http://studios.disneyresearch.com/2020/06/29/high-resolution-neural-face-swapping-for-visual-effects/)
* `EGSR2018` Deep Painterly Harmonization [[code]](https://github.com/luanfujun/deep-painterly-harmonization)
